@misc{ATI_taxonomy,
 archiveprefix = {arXiv},
 author = {Vaishak Belle and Ioannis Papantonis},
 eprint = {2009.11698},
 primaryclass = {cs.LG},
 title = {Principles and Practice of Explainable Machine Learning},
 year = {2020}
}

@misc{shapTree,
 archiveprefix = {arXiv},
 author = {Scott M. Lundberg and Gabriel Erion and Hugh Chen and Alex DeGrave and Jordan M. Prutkin and Bala Nair and Ronit Katz and Jonathan Himmelfarb and Nisha Bansal and Su-In Lee},
 eprint = {1905.04610},
 primaryclass = {cs.LG},
 title = {Explainable AI for Trees: From Local Explanations to Global Understanding},
 year = {2019}
}

@inproceedings{ribeiro2016why,
 author = {Marco T{\'{u}}lio Ribeiro and
Sameer Singh and
Carlos Guestrin},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/kdd/Ribeiro0G16.bib},
 booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
13-17, 2016},
 doi = {10.1145/2939672.2939778},
 editor = {Balaji Krishnapuram and
Mohak Shah and
Alexander J. Smola and
Charu C. Aggarwal and
Dou Shen and
Rajeev Rastogi},
 pages = {1135--1144},
 publisher = {{ACM}},
 timestamp = {Fri, 25 Dec 2020 00:00:00 +0100},
 title = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
 url = {https://doi.org/10.1145/2939672.2939778},
 year = {2016}
}

@inproceedings{shapley,
 author = {Scott M. Lundberg and
Su{-}In Lee},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/LundbergL17.bib},
 booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, {USA}},
 editor = {Isabelle Guyon and
Ulrike von Luxburg and
Samy Bengio and
Hanna M. Wallach and
Rob Fergus and
S. V. N. Vishwanathan and
Roman Garnett},
 pages = {4765--4774},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {A Unified Approach to Interpreting Model Predictions},
 url = {https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
 year = {2017}
}

@inproceedings{predictingAdds,
 abstract = {Online advertising allows advertisers to only bid and pay for measurable user responses, such as clicks on ads. As a consequence, click prediction systems are central to most online advertising systems. With over 750 million daily active users and over 1 million active advertisers, predicting clicks on Facebook ads is a challenging machine learning task. In this paper we introduce a model which combines decision trees with logistic regression, outperforming either of these methods on its own by over 3%, an improvement with significant impact to the overall system performance. We then explore how a number of fundamental parameters impact the final prediction performance of our system. Not surprisingly, the most important thing is to have the right features: those capturing historical information about the user or ad dominate other types of features. Once we have the right features and the right model (decisions trees plus logistic regression), other factors play small roles (though even small improvements are important at scale). Picking the optimal handling for data freshness, learning rate schema and data sampling improve the model slightly, though much less than adding a high-value feature, or picking the right model to begin with.},
 address = {New York, NY, USA},
 author = {He, Xinran and Pan, Junfeng and Jin, Ou and Xu, Tianbing and Liu, Bo and Xu, Tao and Shi, Yanxin and Atallah, Antoine and Herbrich, Ralf and Bowers, Stuart and Candela, Joaquin Qui\~{n}onero},
 booktitle = {Proceedings of the Eighth International Workshop on Data Mining for Online Advertising},
 doi = {10.1145/2648584.2648589},
 isbn = {9781450329996},
 location = {New York, NY, USA},
 numpages = {9},
 pages = {1–9},
 publisher = {Association for Computing Machinery},
 series = {ADKDD'14},
 title = {Practical Lessons from Predicting Clicks on Ads at Facebook},
 url = {https://doi.org/10.1145/2648584.2648589},
 year = {2014}
}

@misc{rudin2019stop,
 archiveprefix = {arXiv},
 author = {Cynthia Rudin},
 eprint = {1811.10154},
 primaryclass = {stat.ML},
 title = {Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
 year = {2019}
}

@misc{rf_explainable,
 archiveprefix = {arXiv},
 author = {Gilles Louppe},
 eprint = {1407.7502},
 primaryclass = {stat.ML},
 title = {Understanding Random Forests: From Theory to Practice},
 year = {2015}
}

@inproceedings{xgboost,
 author = {Tianqi Chen and
Carlos Guestrin},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/kdd/ChenG16.bib},
 booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
13-17, 2016},
 doi = {10.1145/2939672.2939785},
 editor = {Balaji Krishnapuram and
Mohak Shah and
Alexander J. Smola and
Charu C. Aggarwal and
Dou Shen and
Rajeev Rastogi},
 pages = {785--794},
 publisher = {{ACM}},
 timestamp = {Sun, 02 Jun 2019 01:00:00 +0200},
 title = {XGBoost: {A} Scalable Tree Boosting System},
 url = {https://doi.org/10.1145/2939672.2939785},
 year = {2016}
}

@inproceedings{explainning_contrastive,
 abstract = {Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at https://github.com/microsoft/DiCE.},
 address = {New York, NY, USA},
 author = {Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
 booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
 doi = {10.1145/3351095.3372850},
 isbn = {9781450369367},
 location = {Barcelona, Spain},
 numpages = {11},
 pages = {607–617},
 publisher = {Association for Computing Machinery},
 series = {FAT* '20},
 title = {Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations},
 url = {https://doi.org/10.1145/3351095.3372850},
 year = {2020}
}

@article{copies,
 author = {I. {Unceta} and J. {Nin} and O. {Pujol}},
 doi = {10.1109/ACCESS.2020.3020638},
 journal = {IEEE Access},
 number = {},
 pages = {160268-160284},
 title = {Copying Machine Learning Classifiers},
 volume = {8},
 year = {2020}
}

@book{christoph_molnar2019_interpretableML,
 author = {Christoph Molnar},
 note = {\url{https://christophm.github.io/interpretable-ml-book/}},
 subtitle = {A Guide for Making Black Box Models Explainable},
 title = {Interpretable Machine Learning},
 year = {2019}
}

@article{exaplaining_explanations_ATI,
 author = {Mittelstadt, Brent and Russell, Chris and Wachter, Sandra},
 doi = {10.1145/3287560.3287574},
 isbn = {9781450361255},
 journal = {Proceedings of the Conference on Fairness, Accountability, and Transparency - FAT*  ’19},
 publisher = {ACM Press},
 title = {Explaining Explanations in AI},
 url = {http://dx.doi.org/10.1145/3287560.3287574},
 year = {2019}
}

@inproceedings{lundberg2017unified,
 author = {Scott M. Lundberg and
Su{-}In Lee},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/LundbergL17.bib},
 booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, {USA}},
 editor = {Isabelle Guyon and
Ulrike von Luxburg and
Samy Bengio and
Hanna M. Wallach and
Rob Fergus and
S. V. N. Vishwanathan and
Roman Garnett},
 pages = {4765--4774},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {A Unified Approach to Interpreting Model Predictions},
 url = {https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
 year = {2017}
}

@article{case_based_explanation,
 author = {Caruana, R., Kangarloo, H., Dionisio, J. D., Sinha, U., & Johnson, D.},
 doi = {10566351},
 isbn = {9781450361255},
 journal = {Proceedings. AMIA Symposium, 212–215.},
 publisher = {ACM Press},
 title = {Case-based explanation of non-case-based learning methods},
 url = {https://pubmed.ncbi.nlm.nih.gov/10566351/},
 year = {1999}
}

@book{statisticallearning,
 added-at = {2008-05-16T16:17:42.000+0200},
 address = {New York, NY, USA},
 author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
 biburl = {https://www.bibsonomy.org/bibtex/2f58afc5c9793fcc8ad8389824e57984c/sb3000},
 interhash = {d585aea274f2b9b228fc1629bc273644},
 intrahash = {f58afc5c9793fcc8ad8389824e57984c},
 keywords = {ml statistics},
 publisher = {Springer New York Inc.},
 series = {Springer Series in Statistics},
 timestamp = {2008-05-16T16:17:43.000+0200},
 title = {The Elements of Statistical Learning},
 year = {2001}
}

@article{friedman2001,
 author = {Friedman, Jerome H.},
 doi = {10.1214/aos/1013203451},
 fjournal = {Annals of Statistics},
 journal = {Ann. Statist.},
 number = {5},
 pages = {1189--1232},
 publisher = {The Institute of Mathematical Statistics},
 title = {Greedy function approximation: A gradient boosting                      machine.},
 url = {https://doi.org/10.1214/aos/1013203451},
 volume = {29},
 year = {2001}
}

@article{bias_correction_gini,
 author = {Marco Sandri and Paola Zuccolotto},
 doi = {10.1198/106186008X344522},
 eprint = {https://doi.org/10.1198/106186008X344522},
 journal = {Journal of Computational and Graphical Statistics},
 number = {3},
 pages = {611-628},
 publisher = {Taylor & Francis},
 title = {A Bias Correction Algorithm for the Gini Variable Importance Measure in Classification Trees},
 url = {https://doi.org/10.1198/106186008X344522},
 volume = {17},
 year = {2008}
}

@inproceedings{variable_imp_decision_trees,
 author = {S. Jalil Kazemitabar and
Arash A. Amini and
Adam Bloniarz and
Ameet S. Talwalkar},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/KazemitabarABT17.bib},
 booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, {USA}},
 editor = {Isabelle Guyon and
Ulrike von Luxburg and
Samy Bengio and
Hanna M. Wallach and
Rob Fergus and
S. V. N. Vishwanathan and
Roman Garnett},
 pages = {426--435},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Variable Importance Using Decision Trees},
 url = {https://proceedings.neurips.cc/paper/2017/hash/5737c6ec2e0716f3d8a7a5c4e0de0d9a-Abstract.html},
 year = {2017}
}

@misc{hinton2015distilling,
 archiveprefix = {arXiv},
 author = {Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
 eprint = {1503.02531},
 primaryclass = {stat.ML},
 title = {Distilling the Knowledge in a Neural Network},
 year = {2015}
}

@misc{ribeiro2016modelagnostic,
 archiveprefix = {arXiv},
 author = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
 eprint = {1606.05386},
 primaryclass = {stat.ML},
 title = {Model-Agnostic Interpretability of Machine Learning},
 year = {2016}
}

@misc{bewareInmates,
 archiveprefix = {arXiv},
 author = {Tim Miller and Piers Howe and Liz Sonenberg},
 eprint = {1712.00547},
 primaryclass = {cs.AI},
 title = {Explainable AI: Beware of Inmates Running the Asylum Or: How I Learnt to Stop Worrying and Love the Social and Behavioural Sciences},
 year = {2017}
}

@misc{distillingTree,
 archiveprefix = {arXiv},
 author = {Nicholas Frosst and Geoffrey Hinton},
 eprint = {1711.09784},
 primaryclass = {cs.LG},
 title = {Distilling a Neural Network Into a Soft Decision Tree},
 year = {2017}
}

@misc{saabas,
 howpublished = {\url{http://blog.datadive.net/interpreting-random-forests/}},
 note = {Accessed: 2020-11-30},
 title = {Interpreting random forests}
}

@inproceedings{metricCounterfactualTrees,
 abstract = {Explainable Machine Learning is an emerging field in the Machine Learning domain. It addresses the explicability of Machine Learning models and the inherent rationale behind model predictions. In the particular case of example-based explanation methods, they are focused on using particular instances, previously defined or created, to explain the behaviour of models or predictions. Counterfactual-based explanation is one of these methods. A counterfactual is an hypothetical instance similar to an example whose explanation is of interest but with different predicted class. This paper presents a relevance metric for counterfactual selection called sGower designed to induce sparsity in Decision Trees models. It works with categorical and continuous features, while considering number of feature changes and distance between the counterfactual and the example. The proposed metric is evaluated against previous relevance metrics on several sets of categorical and continuous data, obtaining on average better results than previous approaches.},
 address = {Cham},
 author = {Fern{\'a}ndez, Rub{\'e}n R.
and de Diego, Isaac Mart{\'i}n
and Ace{\~{n}}a, V{\'i}ctor
and Moguerza, Javier M.
and Fern{\'a}ndez-Isabel, Alberto},
 booktitle = {Intelligent Data Engineering and Automated Learning -- IDEAL 2019},
 editor = {Yin, Hujun
and Camacho, David
and Tino, Peter
and Tall{\'o}n-Ballesteros, Antonio J.
and Menezes, Ronaldo
and Allmendinger, Richard},
 isbn = {978-3-030-33607-3},
 pages = {85--93},
 publisher = {Springer International Publishing},
 title = {Relevance Metric for Counterfactuals Selection in Decision Trees},
 year = {2019}
}

@article{rfCounterfactual,
 abstract = {Nowadays, Machine Learning (ML) models are becoming ubiquitous in today’s society, supporting people with their day-to-day decisions. In this context, Explainable ML is a field of Artificial Intelligence (AI) that focuses on making predictive models and their decisions interpretable by humans, enabling people to trust predictive models and to understand the underlying processes. A counterfactual is an effective type of Explainable ML technique that explains predictions by describing the changes needed in a sample to flip the outcome of the prediction. In this paper, we introduce counterfactual sets, an explanation approach that uses a set of counterfactuals to explain a prediction rather than a single counterfactual, by defining a sub-region of the feature space where the counterfactual holds. A method to extract counterfactual sets from a Random Forest (RF), the RandomForestOptimalCounterfactualSetExtractor(RF−OCSE), is presented. The method is based on a partial fusion of tree predictors from a RF into a single Decision Tree (DT) using a modification of the CART algorithm, and it obtains a counterfactual set that contains the optimal counterfactual. The proposal is validated through several experiments against existing alternatives on ten well-known datasets by comparing the percentage of valid counterfactuals, distance to the factual sample, and counterfactual sets quality.},
 author = {Rubén R. Fernández and Isaac {Martín de Diego} and Víctor Aceña and Alberto Fernández-Isabel and Javier M. Moguerza},
 doi = {https://doi.org/10.1016/j.inffus.2020.07.001},
 issn = {1566-2535},
 journal = {Information Fusion},
 keywords = {Explainable machine learning, Counterfactual sets, Counterfactual, Information fusion, Random forest, Decision tree},
 pages = {196 - 207},
 title = {Random forest explainability using counterfactual sets},
 url = {http://www.sciencedirect.com/science/article/pii/S1566253520303134},
 volume = {63},
 year = {2020}
}

@article{wachter2018counterfactual,
 author = {Wachter, S and Mittelstadt, BDM and Russell, C},
 edition = {},
 editor = {},
 journal = {Harvard Journal of Law and Technology},
 number = {2},
 pages = {841-887},
 publisher = {Harvard Law School},
 school = {},
 series = {},
 title = {Counterfactual explanations without opening the black box: automated decisions and the GDPR},
 volume = {31},
 year = {2018}
}

@article{DBLP:journals/ail/ZliobaiteC16,
 author = {Indre Zliobaite and
Bart Custers},
 doi = {10.1007/s10506-016-9182-5},
 journal = {Artif. Intell. Law},
 number = {2},
 pages = {183--201},
 title = {Using sensitive personal data may be necessary for avoiding discrimination
in data-driven decision models},
 url = {https://doi.org/10.1007/s10506-016-9182-5},
 volume = {24},
 year = {2016}
}

@article{hoeffding,
 author = {Wassily Hoeffding},
 doi = {10.1080/01621459.1963.10500830},
 issue = {301},
 journal = {Journal of the American Statistical Association},
 pages = {13-–30},
 title = {Probability inequalities for sums of bounded random variables},
 url = {http://dx.doi.org/10.1080/01621459.1963.10500830},
 volume = {58},
 year = {1963}
}

@inproceedings{Mounia_counterfactuals,
 author = {Gabriele Tolomei and
Fabrizio Silvestri and
Andrew Haines and
Mounia Lalmas},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/kdd/TolomeiSHL17.bib},
 booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} International Conference on
Knowledge Discovery and Data Mining, Halifax, NS, Canada, August 13
- 17, 2017},
 doi = {10.1145/3097983.3098039},
 pages = {465--474},
 publisher = {{ACM}},
 timestamp = {Fri, 25 Dec 2020 00:00:00 +0100},
 title = {Interpretable Predictions of Tree-based Ensembles via Actionable Feature
Tweaking},
 url = {https://doi.org/10.1145/3097983.3098039},
 year = {2017}
}

@inproceedings{MultiObjectiveCounterfactuals,
 abstract = {Counterfactual explanations are one of the most popular methods to make predictions of black box machine learning models interpretable by providing explanations in the form of `what-if scenarios'. Most current approaches optimize a collapsed, weighted sum of multiple objectives, which are naturally difficult to balance a-priori. We propose the Multi-Objective Counterfactuals (MOC) method, which translates the counterfactual search into a multi-objective optimization problem. Our approach not only returns a diverse set of counterfactuals with different trade-offs between the proposed objectives, but also maintains diversity in feature space. This enables a more detailed post-hoc analysis to facilitate better understanding and also more options for actionable user responses to change the predicted outcome. Our approach is also model-agnostic and works for numerical and categorical input features. We show the usefulness of MOC in concrete cases and compare our approach with state-of-the-art methods for counterfactual explanations.},
 address = {Cham},
 author = {Dandl, Susanne
and Molnar, Christoph
and Binder, Martin
and Bischl, Bernd},
 booktitle = {Parallel Problem Solving from Nature -- PPSN XVI},
 editor = {B{\"a}ck, Thomas
and Preuss, Mike
and Deutz, Andr{\'e}
and Wang, Hao
and Doerr, Carola
and Emmerich, Michael
and Trautmann, Heike},
 isbn = {978-3-030-58112-1},
 pages = {448--469},
 publisher = {Springer International Publishing},
 title = {Multi-Objective Counterfactual Explanations},
 year = {2020}
}

@article{yang_tree_counterfactuals,
 author = {Q. {Yang} and J. {Yin} and C. {Ling} and R. {Pan}},
 doi = {10.1109/TKDE.2007.250584},
 journal = {IEEE Transactions on Knowledge and Data Engineering},
 number = {1},
 pages = {43-56},
 title = {Extracting Actionable Knowledge from Decision Trees},
 volume = {19},
 year = {2007}
}

@article{mythos_interpretability,
 abstract = {Supervised machine-learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world?},
 address = {New York, NY, USA},
 author = {Lipton, Zachary C.},
 doi = {10.1145/3236386.3241340},
 issn = {1542-7730},
 issue_date = {May-June 2018},
 journal = {Queue},
 number = {3},
 numpages = {27},
 pages = {31–57},
 publisher = {Association for Computing Machinery},
 title = {The Mythos of Model Interpretability: In Machine Learning, the Concept of Interpretability is Both Important and Slippery.},
 url = {https://doi.org/10.1145/3236386.3241340},
 volume = {16},
 year = {2018}
}

@inproceedings{optimal_action,
 author = {Zhicheng Cui and
Wenlin Chen and
Yujie He and
Yixin Chen},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/kdd/CuiCHC15.bib},
 booktitle = {Proceedings of the 21th {ACM} {SIGKDD} International Conference on
Knowledge Discovery and Data Mining, Sydney, NSW, Australia, August
10-13, 2015},
 doi = {10.1145/2783258.2783281},
 editor = {Longbing Cao and
Chengqi Zhang and
Thorsten Joachims and
Geoffrey I. Webb and
Dragos D. Margineantu and
Graham Williams},
 pages = {179--188},
 publisher = {{ACM}},
 timestamp = {Tue, 06 Nov 2018 00:00:00 +0100},
 title = {Optimal Action Extraction for Random Forests and Boosted Trees},
 url = {https://doi.org/10.1145/2783258.2783281},
 year = {2015}
}

@article{pedregosa2011scikit,
 author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
 journal = {the Journal of machine Learning research},
 pages = {2825--2830},
 publisher = {JMLR. org},
 title = {Scikit-learn: Machine learning in Python},
 volume = {12},
 year = {2011}
}

@misc{explainabe_public_policy,
 archiveprefix = {arXiv},
 author = {Kasun Amarasinghe and Kit Rodolfa and Hemank Lamba and Rayid Ghani},
 eprint = {2010.14374},
 primaryclass = {cs.LG},
 title = {Explainable Machine Learning for Public Policy: Use Cases, Gaps, and Research Directions},
 year = {2020}
}

@article{xai_concepts,
 abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
 author = {Alejandro {Barredo Arrieta} and Natalia Díaz-Rodríguez and Javier {Del Ser} and Adrien Bennetot and Siham Tabik and Alberto Barbado and Salvador Garcia and Sergio Gil-Lopez and Daniel Molina and Richard Benjamins and Raja Chatila and Francisco Herrera},
 doi = {https://doi.org/10.1016/j.inffus.2019.12.012},
 issn = {1566-2535},
 journal = {Information Fusion},
 keywords = {Explainable Artificial Intelligence, Machine Learning, Deep Learning, Data Fusion, Interpretability, Comprehensibility, Transparency, Privacy, Fairness, Accountability, Responsible Artificial Intelligence},
 pages = {82-115},
 title = {Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
 url = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
 volume = {58},
 year = {2020}
}

@misc{sktools,
 author = {{David {Masip}, Carlos {Mougan}}},
 note = {[Online; accessed 20-August-2020]},
 title = {Sktools:tools to extend sklearn, feature engineering based transformers.},
 url = {https://sktools.readthedocs.io/},
 year = {2020}
}

@inproceedings{AlgRecourse_Counterfactual_Interventions,
 address = {New York, NY, USA},
 author = {Karimi, Amir-Hossein and Sch\"{o}lkopf, Bernhard and Valera, Isabel},
 booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
 doi = {10.1145/3442188.3445899},
 isbn = {9781450383097},
 keywords = {minimal interventions, consequential recommendations, counterfactual explanations, contrastive explanations, algorithmic recourse, causal inference, explainable artificial intelligence},
 location = {Virtual Event, Canada},
 numpages = {10},
 pages = {353–362},
 publisher = {Association for Computing Machinery},
 series = {FAccT '21},
 title = {Algorithmic Recourse: From Counterfactual Explanations to Interventions},
 url = {https://doi.org/10.1145/3442188.3445899},
 year = {2021}
}

@inproceedings{ActionableRecouserLinear,
 abstract = {Classification models are often used to make decisions that affect humans: whether to approve a loan application, extend a job offer, or provide insurance. In such applications, individuals should have the ability to change the decision of the model. When a person is denied a loan by a credit scoring model, for example, they should be able to change the input variables of the model in a way that will guarantee approval. Otherwise, this person will be denied the loan so long as the model is deployed, and -- more importantly --will lack agency over a decision that affects their livelihood.In this paper, we propose to evaluate a linear classification model in terms of recourse, which we define as the ability of a person to change the decision of the model through actionable input variables (e.g., income vs. age or marital status). We present an integer programming toolkit to: (i) measure the feasibility and difficulty of recourse in a target population; and (ii) generate a list of actionable changes for a person to obtain a desired outcome. We discuss how our tools can inform different stakeholders by using them to audit recourse for credit scoring models built with real-world datasets. Our results illustrate how recourse can be significantly affected by common modeling practices, and motivate the need to evaluate recourse in algorithmic decision-making.},
 address = {New York, NY, USA},
 author = {Ustun, Berk and Spangher, Alexander and Liu, Yang},
 booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
 doi = {10.1145/3287560.3287566},
 isbn = {9781450361255},
 keywords = {accountability, credit scoring, recourse, classification, audit, integer programming},
 location = {Atlanta, GA, USA},
 numpages = {10},
 pages = {10–19},
 publisher = {Association for Computing Machinery},
 series = {FAT* '19},
 title = {Actionable Recourse in Linear Classification},
 url = {https://doi.org/10.1145/3287560.3287566},
 year = {2019}
}

@inbook{Chen2021,
 address = {Cham},
 author = {Chen, Hugh
and Lundberg, Scott
and Lee, Su-In},
 booktitle = {Explainable AI in Healthcare and Medicine: Building a Culture of Transparency and Accountability},
 doi = {10.1007/978-3-030-53352-6_24},
 editor = {Shaban-Nejad, Arash
and Michalowski, Martin
and Buckeridge, David L.},
 isbn = {978-3-030-53352-6},
 pages = {261--270},
 publisher = {Springer International Publishing},
 title = {Explaining Models by Propagating Shapley Values of Local Components},
 url = {https://doi.org/10.1007/978-3-030-53352-6_24},
 year = {2021}
}

@inbook{uncertaintyQuinonero,
 author = {Quiñonero-Candela, Joaquin and Rasmussen, Carl and Sinz, Fabian and Bousquet, Olivier and Schölkopf, Bernhard},
 doi = {10.1007/11736790_1},
 pages = {1-27},
 title = {Evaluating Predictive Uncertainty Challenge},
 volume = {3944},
 year = {2006}
}

@article{epistemic_uncertainty,
 author = {Armen Der Kiureghian and Ove Ditlevsen},
 doi = {https://doi.org/10.1016/j.strusafe.2008.06.020},
 issn = {0167-4730},
 journal = {Structural Safety},
 keywords = {Aleatory, Epistemic, Ergodicity, Parameter uncertainty, Predictive models, Probability distribution choice, Statistical dependence, Systems, Time-variant reliability, Uncertainty},
 note = {Risk Acceptance and Risk Communication},
 number = {2},
 pages = {105-112},
 title = {Aleatory or epistemic? Does it matter?},
 url = {https://www.sciencedirect.com/science/article/pii/S0167473008000556},
 volume = {31},
 year = {2009}
}

@inproceedings{utsun_linear_recourse,
 address = {New York, NY, USA},
 author = {Ustun, Berk and Spangher, Alexander and Liu, Yang},
 booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
 isbn = {9781450361255},
 keywords = {credit scoring, integer programming, audit, accountability, recourse, classification},
 location = {Atlanta, GA, USA},
 numpages = {10},
 pages = {10–19},
 publisher = {Association for Computing Machinery},
 series = {FAT* '19},
 title = {Actionable Recourse in Linear Classification},
 url = {https://doi.org/10.1145/3287560.3287566},
 year = {2019}
}

@article{need_for_uncertainty,
 author = {Begoli, Edmon and Bhattacharya, Tanmoy and Kusnezov, Dimitri},
 doi = {10.1038/s42256-018-0004-1},
 journal = {Nature},
 pages = {},
 title = {The need for uncertainty quantification in machine-assisted medical decision making},
 year = {2019}
}

@article{survey_counterfactuals,
 author = {Amir{-}Hossein Karimi and
Gilles Barthe and
Bernhard Sch{\"{o}}lkopf and
Isabel Valera},
 journal = {ArXiv preprint},
 title = {A survey of algorithmic recourse: definitions, formulations, solutions,
and prospects},
 url = {https://arxiv.org/abs/2010.04050},
 volume = {abs/2010.04050},
 year = {2020}
}

@article{intro_uncertainty,
 author = {Hüllermeier, Eyke and Waegeman, Willem},
 doi = {10.1007/s10994-021-05946-3},
 issn = {1573-0565},
 journal = {Machine Learning},
 number = {3},
 pages = {457–506},
 publisher = {Springer Science and Business Media LLC},
 title = {Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods},
 url = {http://dx.doi.org/10.1007/s10994-021-05946-3},
 volume = {110},
 year = {2021}
}

@article{aleatory_epistemic,
 author = {Der Kiureghian, Armen and Ditlevsen, Ove},
 doi = {10.1016/j.strusafe.2008.06.020},
 journal = {Structural Safety},
 pages = {105-112},
 title = {Aleatory or Epistemic? Does It Matter?},
 volume = {31},
 year = {2009}
}

@misc{continual_learning,
 author = {Tom Diethe and Tom Borchert and Eno Thereska and Borja Balle and Neil Lawrence},
 journal = {ArXiv preprint},
 title = {Continual Learning in Practice},
 url = {https://arxiv.org/abs/1903.05202},
 volume = {abs/1903.05202},
 year = {2019}
}

@misc{desiderataECB,
 archiveprefix = {arXiv},
 author = {Carlos Mougan  and Georgios Kanellos and Thomas Gottron},
 eprint = {2107.08045},
 primaryclass = {cs.CY},
 title = {Desiderata for Explainable AI in statistical production systems of the European Central Bank},
 year = {2021}
}

@book{datasetShift,
 author = {Qui{\~n}onero-Candela, Joaquin and Sugiyama, Masashi and Lawrence, Neil D and Schwaighofer, Anton},
 publisher = {Mit Press},
 title = {Dataset shift in machine learning},
 year = {2009}
}

@article{early_drift,
 author = {Baena-García, Manuel and Campo-Ávila, José and Fidalgo-Merino, Raúl and Bifet, Albert and Gavald, Ricard and Morales-Bueno, Rafael},
 pages = {},
 title = {Early Drift Detection Method},
 year = {2006}
}

@inproceedings{trustUncertainty,
 author = {Jasper Snoek and
Yaniv Ovadia and
Emily Fertig and
Balaji Lakshminarayanan and
Sebastian Nowozin and
D. Sculley and
Joshua V. Dillon and
Jie Ren and
Zachary Nado},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/SnoekOFLNSDRN19.bib},
 booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
on Neural Information Processing Systems 2019, NeurIPS 2019, December
8-14, 2019, Vancouver, BC, Canada},
 editor = {Hanna M. Wallach and
Hugo Larochelle and
Alina Beygelzimer and
Florence d'Alch{\'{e}}{-}Buc and
Emily B. Fox and
Roman Garnett},
 pages = {13969--13980},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Can you trust your model's uncertainty? Evaluating predictive uncertainty
under dataset shift},
 url = {https://proceedings.neurips.cc/paper/2019/hash/8558cb408c1d76621371888657d2eb1d-Abstract.html},
 year = {2019}
}

@misc{uci_data,
 author = {Dua, Dheeru and Graff, Casey},
 howpublished = {University of California, Irvine, School of Information and Computer Sciences, \url{http://archive.ics.uci.edu/ml}},
 institution = {University of California, Irvine, School of Information and Computer Sciences},
 title = {{UCI} Machine Learning Repository},
 year = {2017}
}

@misc{the_turing_way_community_2019_3233986,
 author = {The Turing Way Community and
Becky Arnold and
Louise Bowler and
Sarah Gibson and
Patricia Herterich and
Rosie Higman and
Anna Krystalli and
Alexander Morley and
Martin O'Reilly and
Kirstie Whitaker},
 doi = {10.5281/zenodo.3233986},
 note = {{This work was supported by The UKRI Strategic 
Priorities Fund under the EPSRC Grant
EP/T001569/1, particularly the "Tools, Practices
and Systems" theme within that grant, and by The
Alan Turing Institute under the EPSRC grant
EP/N510129/1.}},
 publisher = {Zenodo},
 title = {{The Turing Way: A Handbook for Reproducible Data 
Science}},
 url = {https://doi.org/10.5281/zenodo.3233986},
 version = {v0.0.4},
 year = {2019}
}

@inproceedings{kumar2012bootstrap,
 author = {Kumar, Sricharan and Srivastava, Ashok},
 booktitle = {Proc. 18th ACM SIGKDD Conf. Knowl. Discovery Data Mining},
 title = {Bootstrap prediction intervals in non-parametric regression with applications to anomaly detection},
 year = {2012}
}

@misc{howtowinKaggle,
 author = {Alexander Guschin and Dmitry Ulyanov and Mikhail Trofimov and Dmitry Altukhov and Mario Michaidilis},
 howpublished = {\url{https://www.coursera.org/lecture/competitive-data-science/categorical-and-ordinal-features-qu1TF}},
 note = {Accessed 02/11/20},
 title = {How to Win a Data Science Competition: Learn from Top Kagglers - National Research University Higher School of Economics},
 year = {2018}
}

@misc{ShiftsData,
 archiveprefix = {arXiv},
 author = {Andrey Malinin and Neil Band and Ganshin and Alexander and German Chesnokov and Yarin Gal and Mark J. F. Gales and Alexey Noskov and Andrey Ploskonosov and Liudmila Prokhorenkova and Ivan Provilkov and Vatsal Raina and Vyas Raina and Roginskiy and Denis and Mariya Shmatova and Panos Tigas and Boris Yangel},
 eprint = {2107.07455},
 primaryclass = {cs.LG},
 title = {Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks},
 year = {2021}
}

@inproceedings{wilds,
 author = {Pang Wei Koh and
Shiori Sagawa and
Henrik Marklund and
Sang Michael Xie and
Marvin Zhang and
Akshay Balsubramani and
Weihua Hu and
Michihiro Yasunaga and
Richard Lanas Phillips and
Irena Gao and
Tony Lee and
Etienne David and
Ian Stavness and
Wei Guo and
Berton Earnshaw and
Imran Haque and
Sara M. Beery and
Jure Leskovec and
Anshul Kundaje and
Emma Pierson and
Sergey Levine and
Chelsea Finn and
Percy Liang},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/KohSMXZBHYPGLDS21.bib},
 booktitle = {Proceedings of the 38th International Conference on Machine Learning,
{ICML} 2021, 18-24 July 2021, Virtual Event},
 editor = {Marina Meila and
Tong Zhang},
 pages = {5637--5664},
 publisher = {{PMLR}},
 series = {Proceedings of Machine Learning Research},
 timestamp = {Wed, 25 Aug 2021 01:00:00 +0200},
 title = {{WILDS:} {A} Benchmark of in-the-Wild Distribution Shifts},
 url = {http://proceedings.mlr.press/v139/koh21a.html},
 volume = {139},
 year = {2021}
}

@misc{hendrycks1,
 archiveprefix = {arXiv},
 author = {Dan Hendrycks and Steven Basart and Norman Mu and Saurav Kadavath and Frank Wang and Evan Dorundo and Rahul Desai and Tyler Zhu and Samyak Parajuli and Mike Guo and Dawn Song and Jacob Steinhardt and Justin Gilmer},
 eprint = {2006.16241},
 primaryclass = {cs.CV},
 title = {The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization},
 year = {2021}
}

@inproceedings{hendrycks2,
 author = {Dan Hendrycks and
Thomas G. Dietterich},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/HendrycksD19.bib},
 booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
New Orleans, LA, USA, May 6-9, 2019},
 publisher = {OpenReview.net},
 timestamp = {Thu, 25 Jul 2019 01:00:00 +0200},
 title = {Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
 url = {https://openreview.net/forum?id=HJz6tiCqYm},
 year = {2019}
}

@misc{hendrycks3,
 archiveprefix = {arXiv},
 author = {Dan Hendrycks and Kevin Zhao and Steven Basart and Jacob Steinhardt and Dawn Song},
 eprint = {1907.07174},
 primaryclass = {cs.LG},
 title = {Natural Adversarial Examples},
 year = {2021}
}

@inproceedings{michel2018mtnt,
 address = {Brussels, Belgium},
 author = {Michel, Paul  and
Neubig, Graham},
 booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
 doi = {10.18653/v1/D18-1050},
 pages = {543--553},
 publisher = {Association for Computational Linguistics},
 title = {{MTNT}: A Testbed for Machine Translation of Noisy Text},
 url = {https://aclanthology.org/D18-1050},
 year = {2018}
}

@book{molnar2019,
 author = {Christoph Molnar},
 note = {\url{https://christophm.github.io/interpretable-ml-book/}},
 subtitle = {A Guide for Making Black Box Models Explainable},
 title = {Interpretable Machine Learning},
 year = {2019}
}

@inproceedings{shapNIPS2017,
 author = {Scott M. Lundberg and
Su{-}In Lee},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/LundbergL17.bib},
 booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, {USA}},
 editor = {Isabelle Guyon and
Ulrike von Luxburg and
Samy Bengio and
Hanna M. Wallach and
Rob Fergus and
S. V. N. Vishwanathan and
Roman Garnett},
 pages = {4765--4774},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {A Unified Approach to Interpreting Model Predictions},
 url = {https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
 year = {2017}
}

@article{lundberg2020local2global,
 author = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
 journal = {Nature Machine Intelligence},
 number = {1},
 pages = {2522-5839},
 publisher = {Nature Publishing Group},
 title = {From local explanations to global understanding with explainable AI for trees},
 volume = {2},
 year = {2020}
}

@article{lundberg2018,
 author = { M.Nair {Bala} and  Vavilala {Monica S.} and  Horibe, {Mayumi}, Eisses and  Michael {J}. and Adams {Trevor} and Liston {David E.} and  Low Daniel {King-Wai} and Newman {Shu-Fang}and {Kim Jerry} and Lee {Su-In}},
 journal = {Nature Biomedical Engineering},
 number = {1},
 pages = {749-760},
 publisher = {Nature Publishing Group},
 title = {Explainable machine-learning predictions for the prevention of hypoxaemia during surgery},
 volume = {2},
 year = {2018}
}

@book{mle,
 author = {Andriy Burkov},
 edition = {1},
 isbn = {1999579577},
 publisher = {Kindle Direct Publishing},
 title = {Machine Learning Engineering},
 year = {2020}
}

@misc{bhatt2021uncertainty,
 archiveprefix = {arXiv},
 author = {Umang Bhatt and Javier Antorán and Yunfeng Zhang and Q. Vera Liao and Prasanna Sattigeri and Riccardo Fogliato and Gabrielle Gauthier Melançon and Ranganath Krishnan and Jason Stanley and Omesh Tickoo and Lama Nachman and Rumi Chunara and Madhulika Srikumar and Adrian Weller and Alice Xiang},
 eprint = {2011.07586},
 primaryclass = {cs.CY},
 title = {Uncertainty as a Form of Transparency: Measuring, Communicating, and Using Uncertainty},
 year = {2021}
}

@inproceedings{koh2020understanding,
 author = {Pang Wei Koh and
Percy Liang},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/KohL17.bib},
 booktitle = {Proceedings of the 34th International Conference on Machine Learning,
{ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
 editor = {Doina Precup and
Yee Whye Teh},
 pages = {1885--1894},
 publisher = {{PMLR}},
 series = {Proceedings of Machine Learning Research},
 timestamp = {Wed, 03 Apr 2019 01:00:00 +0200},
 title = {Understanding Black-box Predictions via Influence Functions},
 url = {http://proceedings.mlr.press/v70/koh17a.html},
 volume = {70},
 year = {2017}
}

@inproceedings{sundararajan2017axiomatic,
 author = {Mukund Sundararajan and
Ankur Taly and
Qiqi Yan},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/SundararajanTY17.bib},
 booktitle = {Proceedings of the 34th International Conference on Machine Learning,
{ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
 editor = {Doina Precup and
Yee Whye Teh},
 pages = {3319--3328},
 publisher = {{PMLR}},
 series = {Proceedings of Machine Learning Research},
 timestamp = {Wed, 03 Apr 2019 01:00:00 +0200},
 title = {Axiomatic Attribution for Deep Networks},
 url = {http://proceedings.mlr.press/v70/sundararajan17a.html},
 volume = {70},
 year = {2017}
}

@phdthesis{Gal2016Uncertainty,
 author = {Gal, Yarin},
 school = {University of Cambridge},
 title = {Uncertainty in Deep Learning},
 year = {2016}
}

@inproceedings{gal2016dropout,
 author = {Yarin Gal and
Zoubin Ghahramani},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/GalG16.bib},
 booktitle = {Proceedings of the 33nd International Conference on Machine Learning,
{ICML} 2016, New York City, NY, USA, June 19-24, 2016},
 editor = {Maria{-}Florina Balcan and
Kilian Q. Weinberger},
 pages = {1050--1059},
 publisher = {JMLR.org},
 series = {{JMLR} Workshop and Conference Proceedings},
 timestamp = {Wed, 29 May 2019 01:00:00 +0200},
 title = {Dropout as a Bayesian Approximation: Representing Model Uncertainty
in Deep Learning},
 url = {http://proceedings.mlr.press/v48/gal16.html},
 volume = {48},
 year = {2016}
}

@inproceedings{lakshminarayanan2017simple,
 author = {Balaji Lakshminarayanan and
Alexander Pritzel and
Charles Blundell},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/Lakshminarayanan17.bib},
 booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, {USA}},
 editor = {Isabelle Guyon and
Ulrike von Luxburg and
Samy Bengio and
Hanna M. Wallach and
Rob Fergus and
S. V. N. Vishwanathan and
Roman Garnett},
 pages = {6402--6413},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
 url = {https://proceedings.neurips.cc/paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html},
 year = {2017}
}

@misc{arnez2020,
 author = {Arnez, Fabio and Espinoza, Huáscar and Radermacher, Ansgar and Terrier, François},
 pages = {},
 title = {A Comparison of Uncertainty Estimation Approaches in Deep Learning Components for Autonomous Vehicle Applications},
 year = {2020}
}

@inbook{adversarialUncertainty,
 abstract = {Neural networks are known to be vulnerable to adversarial examples: inputs that are
close to natural inputs but classified incorrectly. In order to better understand
the space of adversarial examples, we survey ten recent proposals that are designed
for detection and compare their efficacy. We show that all can be defeated by constructing
new loss functions. We conclude that adversarial examples are significantly harder
to detect than previously appreciated, and the properties believed to be intrinsic
to adversarial examples are in fact not. Finally, we propose several simple guidelines
for evaluating future proposed defenses.},
 address = {New York, NY, USA},
 author = {Carlini, Nicholas and Wagner, David},
 booktitle = {Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
 isbn = {9781450352024},
 numpages = {12},
 pages = {3–14},
 publisher = {Association for Computing Machinery},
 title = {Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods},
 url = {https://doi.org/10.1145/3128572.3140444},
 year = {2017}
}

@inproceedings{smith2018understanding,
 author = {Lewis Smith and
Yarin Gal},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/uai/SmithG18.bib},
 booktitle = {Proceedings of the Thirty-Fourth Conference on Uncertainty in Artificial
Intelligence, {UAI} 2018, Monterey, California, USA, August 6-10,
2018},
 editor = {Amir Globerson and
Ricardo Silva},
 pages = {560--569},
 publisher = {{AUAI} Press},
 timestamp = {Thu, 12 Mar 2020 00:00:00 +0100},
 title = {Understanding Measures of Uncertainty for Adversarial Example Detection},
 url = {http://auai.org/uai2018/proceedings/papers/207.pdf},
 year = {2018}
}

@inproceedings{kirsch2019batchbald,
 author = {Andreas Kirsch and
Joost van Amersfoort and
Yarin Gal},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/KirschAG19.bib},
 booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
on Neural Information Processing Systems 2019, NeurIPS 2019, December
8-14, 2019, Vancouver, BC, Canada},
 editor = {Hanna M. Wallach and
Hugo Larochelle and
Alina Beygelzimer and
Florence d'Alch{\'{e}}{-}Buc and
Emily B. Fox and
Roman Garnett},
 pages = {7024--7035},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian
Active Learning},
 url = {https://proceedings.neurips.cc/paper/2019/hash/95323660ed2124450caaac2c46b5ed90-Abstract.html},
 year = {2019}
}

@book{weapons_math,
 address = {USA},
 author = {O'Neil, Cathy},
 isbn = {0553418815},
 publisher = {Crown Publishing Group},
 title = {Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy},
 year = {2016}
}

@inproceedings{ShouldNotTrustMe,
 author = {B. Dimanov and Umang Bhatt and Mateja Jamnik and Adrian Weller},
 booktitle = {SafeAI@AAAI},
 title = {You Shouldn't Trust Me: Learning Models Which Conceal Unfairness From Multiple Explanation Methods},
 year = {2020}
}

@misc{ntoutsi2020bias,
 archiveprefix = {arXiv},
 author = {Eirini Ntoutsi and Pavlos Fafalios and Ujwal Gadiraju and Vasileios Iosifidis and Wolfgang Nejdl and Maria-Esther Vidal and Salvatore Ruggieri and Franco Turini and Symeon Papadopoulos and Emmanouil Krasanakis and Ioannis Kompatsiaris and Katharina Kinder-Kurlanda and Claudia Wagner and Fariba Karimi and Miriam Fernandez and Harith Alani and Bettina Berendt and Tina Kruegel and Christian Heinze and Klaus Broelemann and Gjergji Kasneci and Thanassis Tiropanis and Steffen Staab},
 eprint = {2001.09762},
 primaryclass = {cs.CY},
 title = {Bias in Data-driven AI Systems -- An Introductory Survey},
 year = {2020}
}

@misc{weller2019transparency,
 archiveprefix = {arXiv},
 author = {Adrian Weller},
 eprint = {1708.01870},
 primaryclass = {cs.CY},
 title = {Transparency: Motivations and Challenges},
 year = {2019}
}

@misc{doshivelez2017rigorous,
 archiveprefix = {arXiv},
 author = {Finale Doshi-Velez and Been Kim},
 eprint = {1702.08608},
 primaryclass = {stat.ML},
 title = {Towards A Rigorous Science of Interpretable Machine Learning},
 year = {2017}
}

@article{paco_herrera_xai_taxonomi,
 author = {Alejandro {Barredo Arrieta} and Natalia Díaz-Rodríguez and Javier {Del Ser} and Adrien Bennetot and Siham Tabik and Alberto Barbado and Salvador Garcia and Sergio Gil-Lopez and Daniel Molina and Richard Benjamins and Raja Chatila and Francisco Herrera},
 issn = {1566-2535},
 journal = {Information Fusion},
 keywords = {Explainable Artificial Intelligence, Machine Learning, Deep Learning, Data Fusion, Interpretability, Comprehensibility, Transparency, Privacy, Fairness, Accountability, Responsible Artificial Intelligence},
 pages = {82-115},
 title = {Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
 volume = {58},
 year = {2020}
}

@article{guidotti_survey,
 address = {New York, NY, USA},
 articleno = {93},
 author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
 issn = {0360-0300},
 issue_date = {January 2019},
 journal = {ACM Comput. Surv.},
 keywords = {Open the black box, interpretability, explanations, transparent models},
 number = {5},
 numpages = {42},
 publisher = {Association for Computing Machinery},
 title = {A Survey of Methods for Explaining Black Box Models},
 volume = {51},
 year = {2018}
}

@inproceedings{explaining_explanations_overview_of_interpretability,
 author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
 booktitle = {2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA)},
 number = {},
 pages = {80-89},
 title = {Explaining Explanations: An Overview of Interpretability of Machine Learning},
 volume = {},
 year = {2018}
}

@phdthesis{malinin2019uncertainty,
 author = {Malinin, Andrey},
 school = {University of Cambridge},
 title = {Uncertainty estimation in deep learning with application to spoken language assessment},
 year = {2019}
}

@article{SHIMODAIRA2000227,
 author = {Hidetoshi Shimodaira},
 doi = {https://doi.org/10.1016/S0378-3758(00)00115-4},
 issn = {0378-3758},
 journal = {Journal of Statistical Planning and Inference},
 keywords = {Akaike information criterion, Design of experiments, Importance sampling, Kullback–Leibler divergence, Misspecification, Sample surveys, Weighted least squares},
 number = {2},
 pages = {227-244},
 title = {Improving predictive inference under covariate shift by weighting the log-likelihood function},
 url = {https://www.sciencedirect.com/science/article/pii/S0378375800001154},
 volume = {90},
 year = {2000}
}

@article{humanheight,
 author = {Max Roser, Cameron Appel and Hannah Ritchie},
 journal = {Our World in Data},
 note = {https://ourworldindata.org/human-height},
 title = {Human Height},
 year = {2013}
}

@article{sugiyama,
 author = {Masashi Sugiyama and Matthias Krauledat and Klaus-Robert M{{\"u}}ller},
 journal = {Journal of Machine Learning Research},
 number = {35},
 pages = {985-1005},
 title = {Covariate Shift Adaptation by Importance Weighted Cross Validation},
 url = {http://jmlr.org/papers/v8/sugiyama07a.html},
 volume = {8},
 year = {2007}
}

@article{sugiyama2,
 author = {Sugiyama Masashi and Müller Klaus-Robert},
 doi = {10.1524/stnd.2005.23.4.24},
 journal = {Statistics \& Risk Modeling},
 keywords = {},
 number = {4/2005},
 pages = {249-279},
 title = {{Input-dependent estimation of generalization error under covariate shift}},
 url = {https://ideas.repec.org/a/bpj/strimo/v23y2005i4-2005p249-279n1.html},
 volume = {23},
 year = {2005}
}

@article{priorShift,
 author = {Dirk Tasche},
 journal = {Journal of Machine Learning Research},
 number = {95},
 pages = {1-32},
 title = {Fisher Consistency for Prior Probability Shift},
 url = {http://jmlr.org/papers/v18/17-048.html},
 volume = {18},
 year = {2017}
}

@inproceedings{learningSampleSelection,
 author = {Bianca Zadrozny},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/Zadrozny04.bib},
 booktitle = {Machine Learning, Proceedings of the Twenty-first International Conference
{(ICML} 2004), Banff, Alberta, Canada, July 4-8, 2004},
 doi = {10.1145/1015330.1015425},
 editor = {Carla E. Brodley},
 publisher = {{ACM}},
 series = {{ACM} International Conference Proceeding Series},
 timestamp = {Tue, 06 Nov 2018 00:00:00 +0100},
 title = {Learning and evaluating classifiers under sample selection bias},
 url = {https://doi.org/10.1145/1015330.1015425},
 volume = {69},
 year = {2004}
}

@article{intuitionSampleSelection,
 author = {Ross M. Stolzenberg and Daniel A. Relles},
 issn = {00031224},
 journal = {American Sociological Review},
 number = {3},
 pages = {494--507},
 publisher = {[American Sociological Association, Sage Publications, Inc.]},
 title = {Tools for Intuition about Sample Selection Bias and Its Correction},
 url = {http://www.jstor.org/stable/2657318},
 volume = {62},
 year = {1997}
}

@article{varietiesSelectionBias,
 author = {Heckman, James},
 journal = {American Economic Review},
 number = {2},
 pages = {313-18},
 title = {Varieties of Selection Bias},
 url = {https://EconPapers.repec.org/RePEc:aea:aecrev:v:80:y:1990:i:2:p:313-18},
 volume = {80},
 year = {1990}
}

@misc{cortes2008sample,
 archiveprefix = {arXiv},
 author = {Corinna Cortes and Mehryar Mohri and Michael Riley and Afshin Rostamizadeh},
 eprint = {0805.2775},
 primaryclass = {cs.LG},
 title = {Sample Selection Bias Correction Theory},
 year = {2008}
}

@inproceedings{CorrectingSampleSelection,
 author = {Jiayuan Huang and
Alexander J. Smola and
Arthur Gretton and
Karsten M. Borgwardt and
Bernhard Sch{\"{o}}lkopf},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/HuangSGBS06.bib},
 booktitle = {Advances in Neural Information Processing Systems 19, Proceedings
of the Twentieth Annual Conference on Neural Information Processing
Systems, Vancouver, British Columbia, Canada, December 4-7, 2006},
 editor = {Bernhard Sch{\"{o}}lkopf and
John C. Platt and
Thomas Hofmann},
 pages = {601--608},
 publisher = {{MIT} Press},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Correcting Sample Selection Bias by Unlabeled Data},
 url = {https://proceedings.neurips.cc/paper/2006/hash/a2186aa7c086b46ad4e8bf81e2a3a19b-Abstract.html},
 year = {2006}
}

@article{AInow2018,
 author = {Whittaker, Meredith and Crawford, Kate and Dobbe, Roel and Fried, Genevieve and Kaziunas, Elizabeth and Mathur, Varoon and West, Sarah Myers and Richardson, Rashida and Schultz, Jason and Schwartz, Oscar},
 journal = {New York: AI Now Institute},
 title = {AI Now 2018 report},
 year = {2018}
}

@misc{ainow2019,
 author = {Crawford, Kate and Dobbe, Roel and Dryer, Theodora and Fried, Genevieve and Green, Ben and Kaziunas, Elizabeth and Kak, Amba and Mathur, Varoon and McElroy, Erin and S{\'a}nchez, A and others},
 title = {AI Now 2019 Report. New York: AI Now Institute},
 year = {2019}
}

@misc{learned2020facial,
 author = {Learned-Miller, Erik and Ord{\'o}{\~n}ez, Vicente and Morgenstern, Jamie and Buolamwini, Joy},
 title = {Facial Recognition Technologies in the Wild},
 year = {2020}
}

@inproceedings{practicalFB,
 author = {He, Xinran and Pan, Junfeng and Jin, Ou and Xu, Tianbing and Liu, Bo and Xu, Tao and Shi, Yanxin and Atallah, Antoine and Herbrich, Ralf and Bowers, Stuart and others},
 booktitle = {Proceedings of the Eighth International Workshop on Data Mining for Online Advertising},
 pages = {1--9},
 title = {Practical lessons from predicting clicks on ads at facebook},
 year = {2014}
}

@misc{psi_blog,
 author = {{Matthew Burke}},
 note = {[Online; accessed 9-November-2021]},
 title = {What is the population stability index (PSI)?},
 url = {https://mwburke.github.io/data%20science/2018/04/29/population-stability-index.html},
 year = {2021}
}

@misc{psi_paper,
 author = {{Alec Zhixiao Lin \and LoanDepot \and Foothill Ranch}},
 note = {[Online; accessed 7-November-2021]},
 title = {Examining Distributional Shifts by Using Population Stability Index (PSI) for Model Validation and Diagnosis},
 url = {https://www.lexjansen.com/wuss/2017/47_Final_Paper_PDF.pdf},
 year = {2021}
}

@misc{wiki_ks,
 author = {{{W}ikipedia{,} The Free Encyclopedia}},
 note = {[Online; accessed 12-October-2021]},
 title = {Kolmogorov–Smirnov test},
 url = {https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test},
 year = {2021}
}

@misc{dangelo2021uncertaintybased,
 archiveprefix = {arXiv},
 author = {Francesco D'Angelo and Christian Henning},
 eprint = {2110.06020},
 primaryclass = {cs.LG},
 title = {Uncertainty-based out-of-distribution detection requires suitable function space priors},
 year = {2021}
}

@misc{unc_ood_class,
 author = {Balaji Lakshminarayanan},
 title = {Uncertainty and Out-of-Distribution Robustness in Deep Learning},
 url = {"http://www.gatsby.ucl.ac.uk/~balaji/mluq-talk-balaji.pdf"},
 year = {2021}
}

@book{Jaynes2003,
 author = {E. T. Jaynes},
 publisher = {Cambridge University Press},
 title = {Probability Theory: The Logic of Science},
 year = {2003}
}

@online{one_hot,
 author = {Bruin, J.},
 title = {newtest: command to compute new test {@ONLINE}},
 url = {https://stats.idre.ucla.edu/stata/ado/analysis/},
 year = {2011}
}

@online{ordinal,
 author = {Gregory Carey},
 title = {Coding Categorical Variables},
 url = {http://psych.colorado.edu/~carey/Courses/PSYC5741/handouts/Coding\ 20Categorical\% 20Variables\% 202006-03-03.pdf},
 year = {2003}
}

@article{high-cardinality-categorical,
 address = {New York, NY, USA},
 author = {Micci-Barreca, Daniele},
 issn = {1931-0145},
 issue_date = {July 2001},
 journal = {SIGKDD Explor. Newsl.},
 keywords = {categorical attributes, empirical bayes, hierarchical attributes, predictive models, neural networks},
 number = {1},
 numpages = {6},
 pages = {27–32},
 publisher = {Association for Computing Machinery},
 title = {A Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction Problems},
 volume = {3},
 year = {2001}
}

@article{scikit-learn,
 author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal = {Journal of Machine Learning Research},
 pages = {2825--2830},
 title = {Scikit-learn: Machine Learning in {P}ython},
 volume = {12},
 year = {2011}
}

@book{InterpretableML,
 author = {Christoph Molnar},
 note = {\url{https://christophm.github.io/interpretable-ml-book/}},
 subtitle = {A Guide for Making Black Box Models Explainable},
 title = {Interpretable Machine Learning},
 year = {2019}
}

@misc{wiki:additive-smoothing,
 author = {{Wikipedia contributors}},
 title = {Additive smoothing --- {Wikipedia}{,} The Free Encyclopedia},
 url = {https://en.wikipedia.org/w/index.php?title=Additive\_smoothing\&oldid=937083796},
 year = {2020}
}

@software{turing,
 author = {\mbox{The Turing Way Community}},
 publisher = {Zenodo},
 title = {{The Turing Way: A Handbook for Reproducible Data 
Science}},
 url = {https://doi.org/10.5281/zenodo.3233986},
 year = {2019}
}

@article{comparingClassifiers,
 adsnote = {Provided by the SAO/NASA Astrophysics Data System},
 adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160604316B},
 archiveprefix = {arXiv},
 author = {{Benavoli}, Alessio and {Corani}, Giorgio and {Demsar}, Janez and
{Zaffalon}, Marco},
 eid = {arXiv:1606.04316},
 eprint = {1606.04316},
 journal = {arXiv e-prints},
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
 pages = {arXiv:1606.04316},
 primaryclass = {stat.ML},
 title = {{Time for a change: a tutorial for comparing multiple classifiers through Bayesian analysis}},
 year = {2016}
}

@misc{qe_experiments,
 author = {{David {Masip}, Carlos {Mougan}}},
 title = {Quantile Encoder Experiments},
 url = {https://github.com/david26694/QE\_experiments},
 year = {2020}
}

@misc{category_encoders,
 author = {{Will McGinnis}},
 title = {Category Encoders :A library of sklearn compatible categorical variable encoders.},
 url = {https://contrib.scikit-learn.org/},
 year = {2020}
}

@article{catFeatBayesian,
 adsnote = {Provided by the SAO/NASA Astrophysics Data System},
 adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190413001S},
 archiveprefix = {arXiv},
 author = {{Slakey}, Austin and {Salas}, Daniel and {Schamroth}, Yoni},
 eid = {arXiv:1904.13001},
 eprint = {1904.13001},
 journal = {arXiv e-prints},
 keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
 pages = {arXiv:1904.13001},
 primaryclass = {cs.LG},
 title = {{Encoding Categorical Variables with Conjugate Bayesian Models for WeWork Lead Scoring Engine}},
 year = {2019}
}

@inproceedings{mestimator,
 abstract = {In this paper we introduce a new method for decision tree pruning, based on the minimisation of the expected classification error method by Niblett and Bratko. The original Niblett-Bratko pruning algorithm uses Laplace probability estimates. Here we introduce a new, more general Bayesian approach to estimating probabilities which we call m-probability-estimation. By varying a parameter m in this method, tree pruning can be adjusted to particular properties of the learning domain, such as level of noise. The resulting pruning method improves on the original Niblett-Bratko pruning in the following respects: apriori probabilities can be incorporated into error estimation, several trees pruned to various degrees can be generated, and the degree of pruning is not affected by the number of classes. These improvements are supported by experimental findings. m-probability-estimation also enables the combination of learning data obtained from various sources.},
 address = {Berlin, Heidelberg},
 author = {Cestnik, Bojan
and Bratko, Ivan},
 booktitle = {Machine Learning --- EWSL-91},
 editor = {Kodratoff, Yves},
 isbn = {978-3-540-46308-5},
 pages = {138--150},
 publisher = {Springer Berlin Heidelberg},
 title = {On estimating probabilities in tree pruning},
 year = {1991}
}

@misc{weworkEncoding,
 archiveprefix = {arXiv},
 author = {Austin Slakey and Daniel Salas and Yoni Schamroth},
 eprint = {1904.13001},
 primaryclass = {cs.LG},
 title = {Encoding Categorical Variables with Conjugate Bayesian Models for WeWork Lead Scoring Engine},
 year = {2019}
}

@misc{so2019,
 author = {{Stackoverflow}},
 title = {Developer Survey Results
2019},
 url = {https://insights.stackoverflow.com/survey/2019/},
 year = {2019}
}

@misc{so2018,
 author = {{Stackoverflow}},
 title = {Developer Survey Results
2018},
 url = {https://insights.stackoverflow.com/survey/2018/},
 year = {2018}
}

@misc{ksdata,
 author = {{Kaggle}},
 note = {[Online; accessed 20-October-2020]},
 title = {Kickstarter Projects},
 url = {https://www.kaggle.com/kemical/kickstarter-projects},
 year = {2020}
}

@inproceedings{catboost-encoder,
 author = {Liudmila Ostroumova Prokhorenkova and
Gleb Gusev and
Aleksandr Vorobev and
Anna Veronika Dorogush and
Andrey Gulin},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/ProkhorenkovaGV18.bib},
 booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
on Neural Information Processing Systems 2018, NeurIPS 2018, December
3-8, 2018, Montr{\'{e}}al, Canada},
 editor = {Samy Bengio and
Hanna M. Wallach and
Hugo Larochelle and
Kristen Grauman and
Nicol{\`{o}} Cesa{-}Bianchi and
Roman Garnett},
 pages = {6639--6649},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {CatBoost: unbiased boosting with categorical features},
 url = {https://proceedings.neurips.cc/paper/2018/hash/14491b756b3a51daac41c24863285549-Abstract.html},
 year = {2018}
}

@misc{wiki:contour,
 author = {{Wikipedia contributors}},
 title = {Contour line --- {W}ikipedia{,} The Free Encyclopedia},
 url = {hhttps://en.wikipedia.org/wiki/Contour\_line},
 year = {2004}
}

@article{eNet,
 author = {Hui Zou and Trevor Hastie},
 journal = {Journal of the Royal Statistical Society, Series B},
 pages = {301--320},
 title = {Regularization and variable selection via the Elastic Net},
 year = {2005}
}

@article{eNet2,
 author = {Wang, Li and Zhu, Ji and Zou, Hui},
 journal = {Statistica Sinica},
 pages = {589-615},
 title = {The doubly regularized support vector machine},
 volume = {16},
 year = {2006}
}

@book{hands-on,
 added-at = {2018-04-06T05:58:31.000+0200},
 address = {Sebastopol, CA},
 author = {G\'{e}ron, Aur\'{e}lien},
 biburl = {https://www.bibsonomy.org/bibtex/2a91270a3a516f4edaa5d459c40317fcc/achakraborty},
 interhash = {e2bd4a803c6cba6cca1d926b393806ad},
 intrahash = {a91270a3a516f4edaa5d459c40317fcc},
 isbn = {978-1491962299},
 keywords = {2017 book machine-learning oreilly tensorflow textbook},
 publisher = {O'Reilly Media},
 timestamp = {2018-04-06T05:59:31.000+0200},
 title = {Hands-on machine learning with Scikit-Learn and TensorFlow : concepts, tools, and techniques to build intelligent systems},
 year = {2017}
}

@book{Wilcoxon1992,
 author = {Wilcoxon, Frank},
 booktitle = {Breakthroughs in Statistics: Methodology and Distribution},
 doi = {10.1007/978-1-4612-4380-9\_16},
 isbn = {978-1-4612-4380-9},
 pages = {196--202},
 publisher = {Springer New York},
 title = {Individual Comparisons by Ranking Methods},
 year = {1992}
}

@book{tutz_2011,
 author = {Tutz, Gerhard},
 collection = {Cambridge Series in Statistical and Probabilistic Mathematics},
 doi = {10.1017/CBO9780511842061},
 place = {Cambridge},
 publisher = {Cambridge University Press},
 series = {Cambridge Series in Statistical and Probabilistic Mathematics},
 title = {Regression for Categorical Data},
 year = {2011}
}

@mastersthesis{Pargent:2019,
 author = {F. Pargent and B. Bischl and J. Thomas},
 institution = {Ludwig-Maximilians-Universität},
 school = {School of Statistics},
 title = {A benchmark experiment on how to encode categorical features in predictive modeling},
 year = {2019}
}

@misc{labelEncodingCoursera,
 author = {Alexander Guschin and Dmitry Ulyanov and Mikhail Trofimov and Dmitry Altukhov and Mario Michaidilis},
 howpublished = {\url{https://www.coursera.org/lecture/competitive-data-science/categorical-and-ordinal-features-qu1TF}},
 note = {Accessed 02/11/20},
 title = {How to Win a Data Science Competition: Learn from Top Kagglers - National Research University Higher School of Economics},
 year = {2018}
}

@misc{labelEncodingMedium,
 author = {Sunny Srinidhi},
 howpublished = {\url{https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621}},
 note = {Accessed 02/11/20},
 title = {Label Encoder vs. One Hot Encoder in Machine Learning},
 year = {2018}
}

@inproceedings{frec_enc,
 author = {A. {Uyar} and A. {Bener} and H. N. {Ciray} and M. {Bahceci}},
 booktitle = {2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
 doi = {10.1109/IEMBS.2009.5334548},
 number = {},
 pages = {6214-6217},
 title = {A frequency based encoding technique for transformation of categorical variables in mixed IVF dataset},
 volume = {},
 year = {2009}
}

@misc{medical_payments,
 author = {\mbox{CMS.gov Centers for Medicare \& Medicaid Services}},
 note = {data retrieved from Center for Medicare and Medicaid Services, 
\url{https://www.cms.gov/OpenPayments/Explore-the-Data/Dataset-Downloads}},
 title = {Medical Payments Dataset},
 year = {2020}
}

@article{jamesstein_1,
 abstract = {This article reviews the state of multiparameter shrinkage estimators with emphasis on the empirical Bayes viewpoint, particularly in the case of parametric prior distributions. Some successful applications of major importance are considered. Recent results concerning estimates of error and confidence intervals are described and illustrated with data.},
 author = {Carl N. Morris},
 issn = {01621459},
 journal = {Journal of the American Statistical Association},
 number = {381},
 pages = {47--55},
 publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
 title = {Parametric Empirical Bayes Inference: Theory and Applications},
 volume = {78},
 year = {1983}
}

@article{jamesstein_2,
 abstract = { Statistical analysis of mobility tables has long played a pivotal role in comparative stratification research. This article proposes a shrinkage estimator of the log-odds ratio for comparing mobility tables. Building on an empirical Bayes framework, the shrinkage estimator improves estimation efficiency by “borrowing strength” across multiple tables while placing no restrictions on the pattern of association within tables. Numerical simulation shows that the shrinkage estimator outperforms the usual maximum likelihood estimator (MLE) in both the total squared error and the correlation with the true values. Moreover, the benefits of the shrinkage estimator relative to the MLE depend on both the variation in the true log-odds ratio and the variation in sample size among mobility regimes. To illustrate the effects of shrinkage, the author contrasts the shrinkage estimates with the usual estimates for the mobility data assembled by Hazelrigg and Garnier for 16 countries in the 1960s and 1970s. For mobility tables with more than two categories, the shrinkage estimates of log-odds ratios can also be used to calculate summary measures of association that are based on aggregations of log-odds ratios. Specifically, the author constructs an adjusted estimator of the Altham index and, with a set of calibrated simulations, demonstrates its usefulness in enhancing both the precision of individual estimates and the accuracy of cross-table comparisons. Finally, using two real data sets, the author shows that in gauging the overall degree of social fluidity, the adjusted estimator of the Altham index agrees more closely with results from the Unidiff model than does the direct estimator of the Altham index. },
 author = {Xiang Zhou},
 journal = {Sociological Methodology},
 number = {1},
 pages = {320-356},
 title = {Shrinkage Estimation of Log-odds Ratios for Comparing Mobility Tables},
 volume = {45},
 year = {2015}
}

@article{jamesstein_3,
 author = {Efron, Bradley and Morris, Carl},
 doi = {10.1038/scientificamerican0577-119},
 journal = {Scientific American - SCI AMER},
 pages = {119-127},
 title = {Stein's Paradox in Statistics},
 volume = {236},
 year = {1977}
}

@book{mixed_models,
 author = {Gelman, Andrew and Hill, Jennifer},
 collection = {Analytical Methods for Social Research},
 doi = {10.1017/CBO9780511790942},
 place = {Cambridge},
 publisher = {Cambridge University Press},
 series = {Analytical Methods for Social Research},
 title = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
 year = {2006}
}

@misc{median_proof_se,
 author = {{Stack Exchange}},
 title = {The median minimizes the sum of absolute deviations (the ℓ1 norm)},
 url = {https://math.stackexchange.com/questions/113270/the-median-minimizes-the-sum-of-absolute-deviations-the-ell-1-norm},
 year = {2020}
}

@misc{median_proof_ppt,
 author = {{Charles J. Geyer,
School of Statistics,
University of Minnesota}},
 title = {Stat 5101 Lecture Slides},
 url = {https://www.stat.umn.edu/geyer/f11/5101/slides/s4a.pdf},
 year = {2020}
}

@misc{crawford2019ai,
 author = {Crawford, Kate and Dobbe, Roel and Dryer, Theodora and Fried, Genevieve and Green, Ben and Kaziunas, Elizabeth and Kak, Amba and Mathur, Varoon and McElroy, Erin and S{\'a}nchez, A and others},
 title = {AI Now 2019 Report. New York: AI Now Institute},
 year = {2019}
}

@inproceedings{he2014practical,
 author = {He, Xinran and Pan, Junfeng and Jin, Ou and Xu, Tianbing and Liu, Bo and Xu, Tao and Shi, Yanxin and Atallah, Antoine and Herbrich, Ralf and Bowers, Stuart and others},
 booktitle = {Proceedings of the Eighth International Workshop on Data Mining for Online Advertising},
 pages = {1--9},
 title = {Practical lessons from predicting clicks on ads at facebook},
 year = {2014}
}

@article{floridi2019establishing,
 author = {Floridi, Luciano},
 journal = {Nature Machine Intelligence},
 number = {6},
 pages = {261--262},
 publisher = {Nature Publishing Group},
 title = {Establishing the rules for building trustworthy AI},
 volume = {1},
 year = {2019}
}

@article{smuha2019eu,
 author = {Smuha, Nathalie A},
 journal = {Computer Law Review International},
 number = {4},
 pages = {97--106},
 publisher = {Verlag Dr. Otto Schmidt},
 title = {The eu approach to ethics guidelines for trustworthy artificial intelligence},
 volume = {20},
 year = {2019}
}

@article{hancock2020catboost,
 author = {Hancock, John T and Khoshgoftaar, Taghi M},
 journal = {Journal of big data},
 number = {1},
 pages = {1--45},
 publisher = {Springer},
 title = {CatBoost for big data: an interdisciplinary review},
 volume = {7},
 year = {2020}
}

@article{dorogush2018catboost,
 author = {Dorogush, Anna Veronika and Ershov, Vasily and Gulin, Andrey},
 journal = {ArXiv preprint},
 title = {CatBoost: gradient boosting with categorical features support},
 url = {https://arxiv.org/abs/1810.11363},
 volume = {abs/1810.11363},
 year = {2018}
}

@article{huang2019evaluation,
 author = {Huang, Guomin and Wu, Lifeng and Ma, Xin and Zhang, Weiqiang and Fan, Junliang and Yu, Xiang and Zeng, Wenzhi and Zhou, Hanmi},
 journal = {Journal of Hydrology},
 pages = {1029--1041},
 publisher = {Elsevier},
 title = {Evaluation of CatBoost method for prediction of reference evapotranspiration in humid regions},
 volume = {574},
 year = {2019}
}

@inproceedings{zafar2017fairness,
 author = {Muhammad Bilal Zafar and
Isabel Valera and
Manuel Gomez{-}Rodriguez and
Krishna P. Gummadi},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/aistats/ZafarVGG17.bib},
 booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence
and Statistics, {AISTATS} 2017, 20-22 April 2017, Fort Lauderdale,
FL, {USA}},
 editor = {Aarti Singh and
Xiaojin (Jerry) Zhu},
 pages = {962--970},
 publisher = {{PMLR}},
 series = {Proceedings of Machine Learning Research},
 timestamp = {Wed, 03 Apr 2019 01:00:00 +0200},
 title = {Fairness Constraints: Mechanisms for Fair Classification},
 url = {http://proceedings.mlr.press/v54/zafar17a.html},
 volume = {54},
 year = {2017}
}

@inproceedings{DBLP:conf/www/ZafarVGG17,
  author    = {Muhammad Bilal Zafar and
               Isabel Valera and
               Manuel Gomez{-}Rodriguez and
               Krishna P. Gummadi},
  editor    = {Rick Barrett and
               Rick Cummings and
               Eugene Agichtein and
               Evgeniy Gabrilovich},
  title     = {Fairness Beyond Disparate Treatment {\&} Disparate Impact: Learning
               Classification without Disparate Mistreatment},
  booktitle = {Proceedings of the 26th International Conference on World Wide Web,
               {WWW} 2017, Perth, Australia, April 3-7, 2017},
  pages     = {1171--1180},
  publisher = {{ACM}},
  year      = {2017},
  url       = {https://doi.org/10.1145/3038912.3052660},
  doi       = {10.1145/3038912.3052660},
  timestamp = {Tue, 06 Nov 2018 16:57:10 +0100},
  biburl    = {https://dblp.org/rec/conf/www/ZafarVGG17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{zafat2017fairnessDisparate,
 author = {Zafar, Muhammad Bilal and Valera, Isabel and Gomez Rodriguez, Manuel and Gummadi, Krishna P.},
 doi = {10.1145/3038912.3052660},
 journal = {Proceedings of the 26th International Conference on World Wide Web},
 publisher = {International World Wide Web Conferences Steering Committee},
 title = {Fairness Beyond Disparate Treatment \& Disparate Impact},
 url = {http://dx.doi.org/10.1145/3038912.3052660},
 year = {2017}
}

@inproceedings{zafar2017parity,
 author = {Muhammad Bilal Zafar and
Isabel Valera and
Manuel Gomez{-}Rodriguez and
Krishna P. Gummadi and
Adrian Weller},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/ZafarVGGW17.bib},
 booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, {USA}},
 editor = {Isabelle Guyon and
Ulrike von Luxburg and
Samy Bengio and
Hanna M. Wallach and
Rob Fergus and
S. V. N. Vishwanathan and
Roman Garnett},
 pages = {229--239},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {From Parity to Preference-based Notions of Fairness in Classification},
 url = {https://proceedings.neurips.cc/paper/2017/hash/82161242827b703e6acf9c726942a1e4-Abstract.html},
 year = {2017}
}

@article{Barocas2016BigDD,
 author = {Solon Barocas and Andrew D. Selbst},
 journal = {California Law Review},
 pages = {671},
 title = {Big Data's Disparate Impact},
 volume = {104},
 year = {2016}
}

@inproceedings{pedreshi2008discrimination,
 author = {Pedreshi, Dino and Ruggieri, Salvatore and Turini, Franco},
 booktitle = {Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
 pages = {560--568},
 title = {Discrimination-aware data mining},
 year = {2008}
}

@misc{EU_fundamentalrights,
 date = {2012-10-26},
 key = {European Commission},
 organization = {European Commission},
 title = {CHARTER OF FUNDAMENTAL RIGHTS OF THE EUROPEAN UNION},
 url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:12012P/TXT}
}

@misc{gdpr,
 date = {2018-05-25},
 key = {European Commission},
 organization = {European Commission},
 title = {2018 {R}eform of {EU} data protection rules},
 url = {https://ec.europa.eu/commission/sites/beta-political/files/data-protection-factsheet-changes_en.pdf},
 urldate = {2019-06-17}
}

@misc{pargent2021regularized,
 archiveprefix = {arXiv},
 author = {Florian Pargent and Florian Pfisterer and Janek Thomas and Bernd Bischl},
 eprint = {2104.00629},
 primaryclass = {stat.ML},
 title = {Regularized target encoding outperforms traditional methods in supervised machine learning with high cardinality features},
 year = {2021}
}

@article{target_embedding,
 author = {Pau Rodríguez and Miguel A. Bautista and Jordi Gonzàlez and Sergio Escalera},
 doi = {https://doi.org/10.1016/j.imavis.2018.04.004},
 issn = {0262-8856},
 journal = {Image and Vision Computing},
 keywords = {Error correcting output codes, Output embeddings, Deep learning, Computer vision},
 pages = {21-31},
 title = {Beyond one-hot encoding: Lower dimensional target embedding},
 url = {https://www.sciencedirect.com/science/article/pii/S0262885618300623},
 volume = {75},
 year = {2018}
}

@article{natureOHE,
 author = {Okada, Shuntaro and Ohzeki, Masayuki and Taguchi, Shinichiro},
 doi = {10.1038/s41598-019-49539-6},
 journal = {Scientific Reports},
 pages = {},
 title = {Efficient partition of integer optimization problems with one-hot encoding},
 volume = {9},
 year = {2019}
}

@article{negligible2021,
 author = {Rodolfa, Kit T. and Lamba, Hemank and Ghani, Rayid},
 doi = {10.1038/s42256-021-00396-x},
 issn = {2522-5839},
 journal = {Nature Machine Intelligence},
 number = {10},
 pages = {896–904},
 publisher = {Springer Science and Business Media LLC},
 title = {Empirical observation of negligible fairness–accuracy trade-offs in machine learning for public policy},
 url = {http://dx.doi.org/10.1038/s42256-021-00396-x},
 volume = {3},
 year = {2021}
}

@inproceedings{heidari2019fairness,
 author = {Hoda Heidari and
Claudio Ferrari and
Krishna P. Gummadi and
Andreas Krause},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/HeidariFGK18.bib},
 booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
on Neural Information Processing Systems 2018, NeurIPS 2018, December
3-8, 2018, Montr{\'{e}}al, Canada},
 editor = {Samy Bengio and
Hanna M. Wallach and
Hugo Larochelle and
Kristen Grauman and
Nicol{\`{o}} Cesa{-}Bianchi and
Roman Garnett},
 pages = {1273--1283},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Fairness Behind a Veil of Ignorance: {A} Welfare Analysis for Automated
Decision Making},
 url = {https://proceedings.neurips.cc/paper/2018/hash/be3159ad04564bfb90db9e32851ebf9c-Abstract.html},
 year = {2018}
}

@misc{friedler2018comparative,
 archiveprefix = {arXiv},
 author = {Sorelle A. Friedler and Carlos Scheidegger and Suresh Venkatasubramanian and Sonam Choudhary and Evan P. Hamilton and Derek Roth},
 eprint = {1802.04422},
 primaryclass = {stat.ML},
 title = {A comparative study of fairness-enhancing interventions in machine learning},
 year = {2018}
}

@misc{kearns2018empirical,
 archiveprefix = {arXiv},
 author = {Michael Kearns and Seth Neel and Aaron Roth and Zhiwei Steven Wu},
 eprint = {1808.08166},
 primaryclass = {cs.LG},
 title = {An Empirical Study of Rich Subgroup Fairness for Machine Learning},
 year = {2018}
}

@article{rayid2020,
 author = {Rodolfa, Kit T. and Salomon, Erika and Haynes, Lauren and Mendieta, Iván Higuera and Larson, Jamie and Ghani, Rayid},
 doi = {10.1145/3351095.3372863},
 journal = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
 publisher = {ACM},
 title = {Case study},
 url = {http://dx.doi.org/10.1145/3351095.3372863},
 year = {2020}
}

@misc{compass,
 author = {Jeff Larson, Surya Mattu, Lauren Kirchner and Julia Angwin},
 note = {[Online; accessed 21-December-2021]},
 title = {How We Analyzed the COMPAS Recidivism Algorithm},
 url = {https://github.com/propublica/compas-analysis},
 year = {2016}
}

@inproceedings{YangLS21_CausalIntersectionality,
 author = {Ke Yang and
Joshua R. Loftus and
Julia Stoyanovich},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/forc/YangLS21.bib},
 booktitle = {2nd Symposium on Foundations of Responsible Computing, {FORC} 2021,
June 9-11, 2021, Virtual Conference},
 doi = {10.4230/LIPIcs.FORC.2021.7},
 editor = {Katrina Ligett and
Swati Gupta},
 pages = {7:1--7:20},
 publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
 series = {LIPIcs},
 timestamp = {Tue, 01 Jun 2021 18:27:06 +0200},
 title = {Causal Intersectionality and Fair Ranking},
 url = {https://doi.org/10.4230/LIPIcs.FORC.2021.7},
 volume = {192},
 year = {2021}
}

@book{IgnazioKlein2020_DataFeminism,
 author = {D'ignazio, Catherine and Klein, Lauren F},
 publisher = {MIT Press},
 title = {Data Feminism},
 year = {2020}
}

@book{Collins2002_BlackFeminism,
 author = {Collins, Patricia Hill},
 publisher = {Routledge},
 title = {Black feminist thought: Knowledge, consciousness, and the politics of empowerment},
 year = {2002}
}

@inproceedings{FouldsIKP20_IntersectionalDefFairness,
 author = {James R. Foulds and
Rashidul Islam and
Kamrun Naher Keya and
Shimei Pan},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icde/FouldsIKP20.bib},
 booktitle = {36th {IEEE} International Conference on Data Engineering, {ICDE} 2020,
Dallas, TX, USA, April 20-24, 2020},
 doi = {10.1109/ICDE48307.2020.00203},
 pages = {1918--1921},
 publisher = {{IEEE}},
 timestamp = {Fri, 05 Jun 2020 17:54:57 +0200},
 title = {An Intersectional Definition of Fairness},
 url = {https://doi.org/10.1109/ICDE48307.2020.00203},
 year = {2020}
}

@article{Wachter2021_FairnessCantAutomate,
 author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
 journal = {Computer Law \& Security Review},
 pages = {105567},
 publisher = {Elsevier},
 title = {Why fairness cannot be automated: Bridging the gap between {EU} non-discrimination law and {AI}},
 volume = {41},
 year = {2021}
}

@article{RomeiR2014_DiscSurvey,
 author = {Andrea Romei and
Salvatore Ruggieri},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/ker/RomeiR14.bib},
 doi = {10.1017/S0269888913000039},
 journal = {Knowl. Eng. Rev.},
 number = {5},
 pages = {582--638},
 timestamp = {Thu, 27 Aug 2020 13:20:00 +0200},
 title = {A multidisciplinary survey on discrimination analysis},
 url = {https://doi.org/10.1017/S0269888913000039},
 volume = {29},
 year = {2014}
}

@misc{mougan2021desiderata,
 archiveprefix = {arXiv},
 author = {Carlos Mougan Navarro and Georgios Kanellos and Thomas Gottron},
 eprint = {2107.08045},
 primaryclass = {cs.CY},
 title = {Desiderata for Explainable AI in statistical production systems of the European Central Bank},
 year = {2021}
}

@book{Wightman1998_LawDataSource,
 author = {Wightman, Linda F},
 publisher = {Law School Admission Council},
 title = {LSAC national longitudinal bar passage study},
 year = {1998}
}

@inproceedings{KusnerLRS2017_CounterfactualFairness,
 author = {Matt J. Kusner and
Joshua R. Loftus and
Chris Russell and
Ricardo Silva},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/KusnerLRS17.bib},
 booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, {USA}},
 editor = {Isabelle Guyon and
Ulrike von Luxburg and
Samy Bengio and
Hanna M. Wallach and
Rob Fergus and
S. V. N. Vishwanathan and
Roman Garnett},
 pages = {4066--4076},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Counterfactual Fairness},
 url = {https://proceedings.neurips.cc/paper/2017/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html},
 year = {2017}
}

@article{2018aequitas,
 author = {Saleiro, Pedro and Kuester, Benedict and Stevens, Abby and Anisfeld, Ari and Hinkson, Loren and London, Jesse and Ghani, Rayid},
 journal = {ArXiv preprint},
 title = {Aequitas: A Bias and Fairness Audit Toolkit},
 url = {https://arxiv.org/abs/1811.05577},
 volume = {abs/1811.05577},
 year = {2018}
}

@book{ecml2020biasworkshop,
 abstract = {This volume constitutes the refereed proceedings of the workshops which complemented the 20th Joint European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD, held in September 2020. Due to the COVID-19 pandemic the conference and workshops were held online. The 43 papers presented in volume were carefully reviewed and selected from numerous submissions. The volume presents the papers that have been accepted for the following workshops: 5th Workshop on Data Science for Social Good, SoGood 2020; Workshop on Parallel, Distributed and Federated Learning, PDFL 2020; Second Workshop on Machine Learning for Cybersecurity, MLCS 2020, 9th International Workshop on New Frontiers in Mining Complex Patterns, NFMCP 2020, Workshop on Data Integration and Applications, DINA 2020, Second Workshop on Evaluation and Experimental Design in Data Mining and Machine Learning, EDML 2020, Second International Workshop on eXplainable Knowledge Discovery in Data Mining, XKDD 2020; 8th International Workshop on News Recommendation and Analytics, INRA 2020. },
 address = {Germany},
 author = {Albrecht Zimmermann and Eirini Ntoutsi and Erich Schubert},
 doi = {10.1007/978-3-030-65965-3},
 editor = {Irena Koprinska and Michael Kamp and Annalisa Appice and Corrado Loglisci and Luiza Antonie and Riccardo Guidotti and {\"O}zlem {\"O}zg{\"o}bek and Ribeiro, {Rita P.} and Ricard Gavald{\`a} and Jo{\~a}o Gama and Linara Adilova and Yamuna Krishnamurthy and Ferreira, {Pedro M.} and Donato Malerba and Ib{\'e}ria Medeiros and Michelangelo Ceci and Giuseppe Manco and Elio Masciari and Ras, {Zbigniew W.} and Peter Christen and Arthur Zimek and Anna Monreale and Przemyslaw Biecek and Salvatore Rinzivillo and Benjamin Kille and Andreas Lommatzsch and Gulla, {Jon Atle}},
 isbn = {978-3-030-65964-6},
 language = {English},
 note = {Evaluation and Experimental Design in Data Mining and Machine Learning, EDML ; Conference date: 14-09-2020 Through 14-09-2020},
 publisher = {Springer},
 series = {Communications in Computer and Information Science},
 title = {ECML PKDD 2020 Workshops: Workshops of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD 2020): SoGood 2020, PDFL 2020, MLCS 2020, NFMCP 2020, DINA 2020, EDML 2020, XKDD 2020 and INRA 2020, Ghent, Belgium, September 14-18, 2020, Proceedings},
 url = {https://imada.sdu.dk/Research/EDML/2020/},
 year = {2020}
}

@article{specialIssueFairness,
 address = {New York, NY, USA},
 author = {Calders, Toon and Ntoutsi, Eirini and Pechenizkiy, Mykola and Rosenhahn, Bodo and Ruggieri, Salvatore},
 doi = {10.1145/3468507.3468509},
 issn = {1931-0145},
 issue_date = {June 2021},
 journal = {SIGKDD Explor. Newsl.},
 keywords = {fairness, responsible artificial intelligence, fairness-aware machine learning, bias, discrimination},
 number = {1},
 numpages = {3},
 pages = {1–3},
 publisher = {Association for Computing Machinery},
 title = {Introduction to The Special Section on Bias and Fairness in AI},
 url = {https://doi.org/10.1145/3468507.3468509},
 volume = {23},
 year = {2021}
}

@inproceedings{kearns2018preventing,
 author = {Michael J. Kearns and
Seth Neel and
Aaron Roth and
Zhiwei Steven Wu},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/KearnsNRW18.bib},
 booktitle = {Proceedings of the 35th International Conference on Machine Learning,
{ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15,
2018},
 editor = {Jennifer G. Dy and
Andreas Krause},
 pages = {2569--2577},
 publisher = {{PMLR}},
 series = {Proceedings of Machine Learning Research},
 timestamp = {Tue, 08 Oct 2019 01:00:00 +0200},
 title = {Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup
Fairness},
 url = {http://proceedings.mlr.press/v80/kearns18a.html},
 volume = {80},
 year = {2018}
}

@article{japkowicz2002class,
 author = {Japkowicz, Nathalie and Stephen, Shaju},
 journal = {Intelligent data analysis},
 number = {5},
 pages = {429--449},
 publisher = {IOS Press},
 title = {The class imbalance problem: A systematic study},
 volume = {6},
 year = {2002}
}

@inproceedings{finocchiaro2021bridging,
 author = {Finocchiaro, Jessie and Maio, Roland and Monachou, Faidra and Patro, Gourab K and Raghavan, Manish and Stoica, Ana-Andreea and Tsirtsis, Stratis},
 booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
 pages = {489--503},
 title = {Bridging Machine Learning and Mechanism Design towards Algorithmic Fairness},
 year = {2021}
}

@article{mehrabi2021survey,
 author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
 journal = {ACM Computing Surveys (CSUR)},
 number = {6},
 pages = {1--35},
 publisher = {ACM New York, NY, USA},
 title = {A survey on bias and fairness in machine learning},
 volume = {54},
 year = {2021}
}

@techreport{bird2020fairlearn,
 author = {Bird, Sarah and Dud{\'i}k, Miro and Edgar, Richard and Horn, Brandon and Lutz, Roman and Milan, Vanessa and Sameki, Mehrnoosh and Wallach, Hanna and Walker, Kathleen},
 institution = {Microsoft},
 number = {MSR-TR-2020-32},
 title = {Fairlearn: A toolkit for assessing and improving fairness in {AI}},
 url = {https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/},
 year = {2020}
}

@article{flores2016false,
 author = {Flores, Anthony W and Bechtel, Kristin and Lowenkamp, Christopher T},
 journal = {Fed. Probation},
 pages = {38},
 publisher = {HeinOnline},
 title = {False positives, false negatives, and false analyses: A rejoinder to machine bias: There's software used across the country to predict future criminals. and it's biased against blacks},
 volume = {80},
 year = {2016}
}

@misc{aif360-oct-2018,
 author = {Rachel K. E. Bellamy and Kuntal Dey and Michael Hind and
Samuel C. Hoffman and Stephanie Houde and Kalapriya Kannan and
Pranay Lohia and Jacquelyn Martino and Sameep Mehta and
Aleksandra Mojsilovic and Seema Nagar and Karthikeyan Natesan Ramamurthy and
John Richards and Diptikalyan Saha and Prasanna Sattigeri and
Moninder Singh and Kush R. Varshney and Yunfeng Zhang},
 journal = {ArXiv preprint},
 title = {{AI Fairness} 360:  An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias},
 url = {https://arxiv.org/abs/1810.01943},
 volume = {abs/1810.01943},
 year = {2018}
}

@inproceedings{supervised_learning_algorithms,
 author = {Rich Caruana and
Alexandru Niculescu{-}Mizil},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/CaruanaN06.bib},
 booktitle = {Machine Learning, Proceedings of the Twenty-Third International Conference
{(ICML} 2006), Pittsburgh, Pennsylvania, USA, June 25-29, 2006},
 doi = {10.1145/1143844.1143865},
 editor = {William W. Cohen and
Andrew W. Moore},
 pages = {161--168},
 publisher = {{ACM}},
 series = {{ACM} International Conference Proceeding Series},
 timestamp = {Tue, 06 Nov 2018 00:00:00 +0100},
 title = {An empirical comparison of supervised learning algorithms},
 url = {https://doi.org/10.1145/1143844.1143865},
 volume = {148},
 year = {2006}
}

@article{gbm,
 author = {Jerome H. Friedman},
 journal = {The Annals of Statistics},
 keywords = {boosting, decision trees, Function estimation, robust nonparametric regression},
 number = {5},
 pages = {1189 -- 1232},
 publisher = {Institute of Mathematical Statistics},
 title = {{Greedy function approximation: A gradient boosting
machine.}},
 volume = {29},
 year = {2001}
}

@article{gbm_nn,
 author = {Roe, Byron P. and Yang, Hai-Jun and Zhu, Ji and Liu, Yong and Stancu, Ion and McGregor, Gordon},
 issn = {0168-9002},
 journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
 number = {2-3},
 pages = {577–584},
 publisher = {Elsevier BV},
 title = {Boosted decision trees as an alternative to artificial neural networks for particle identification},
 volume = {543},
 year = {2005}
}

@article{gbm_adaptative,
 author = {Wu, Qiang and Burges, Chris J.C. and Svore, Krysta M. and Gao, Jianfeng},
 journal = {Information Retrieval},
 pages = {254-270},
 publisher = {Springer Verlag},
 title = {Adapting Bboosting for Information Retrieval Measures},
 volume = {13},
 year = {2010}
}

@article{gbm_travel,
 author = {Y. Zhang and A. Haghani},
 journal = {Transportation Research Part C-emerging Technologies},
 pages = {308-324},
 title = {A gradient boosting method to improve travel time prediction},
 volume = {58},
 year = {2015}
}

@article{bigdata_potus,
 author = {John Podesta, Penny Pritzker, Ernest J. Moniz, John Holdren, and Jefrey Zients},
 journal = {United States. Executive Office of the President},
 url = {https://www.hsdl.org/?view&did=752636},
 title = {Big data: Seizing opportunities and preserving values},
 year = {2014}
}
@article{bigdata_potus1,
 author = {Cecilia Munoz, Megan Smith, DJ Patil},
 journal = {United States. Executive Office of the President},
 url = {https://www.hsdl.org/?view&did=792977},
 title = {Big data: A report on algorithmic systems, opportunity, and civil right},
 year = {2016}
}

@book{get_bristol,
 author = {Carlos {Mougan} and Qian {Fu} and Jojeena {Kolath} and Huan {Tong} and Siddharth {Dixit} and Laurens {Geffert} and Hyesop {Shin} and Rabuh and {Ahmad Abd} and Caitlin {Robinson} and Ella {Gale}},
 day = {29},
 doi = {10.5281/zenodo.3775497},
 language = {English},
 note = {Turing Network Data Study Group Bristol ; Conference date: 05-08-2019 Through 09-08-2019},
 publisher = {Zenodo},
 title = {Data Study Group Network Final Report: Bristol City Council (Get Bristol moving: tackling air pollution in Bristol city centre)},
 url = {https://www.turing.ac.uk/events/turing-network-data-study-group-bristol-august-2019},
 year = {2020}
}
@inproceedings{DBLP:conf/nips/HardtPNS16,
  author    = {Moritz Hardt and
               Eric Price and
               Nati Srebro},
  editor    = {Daniel D. Lee and
               Masashi Sugiyama and
               Ulrike von Luxburg and
               Isabelle Guyon and
               Roman Garnett},
  title     = {Equality of Opportunity in Supervised Learning},
  booktitle = {Advances in Neural Information Processing Systems 29: Annual Conference
               on Neural Information Processing Systems 2016, December 5-10, 2016,
               Barcelona, Spain},
  pages     = {3315--3323},
  year      = {2016},
  url       = {https://proceedings.neurips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html},
  timestamp = {Thu, 21 Jan 2021 15:15:22 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/HardtPNS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{hartdt_equality,
 author = {Moritz Hardt and
Eric Price and
Nati Srebro},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/HardtPNS16.bib},
 booktitle = {Advances in Neural Information Processing Systems 29: Annual Conference
on Neural Information Processing Systems 2016, December 5-10, 2016,
Barcelona, Spain},
 editor = {Daniel D. Lee and
Masashi Sugiyama and
Ulrike von Luxburg and
Isabelle Guyon and
Roman Garnett},
 pages = {3315--3323},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Equality of Opportunity in Supervised Learning},
 url = {https://proceedings.neurips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html},
 year = {2016}
}

@inproceedings{DworkHPRZ2012_IndFair,
 author = {Cynthia Dwork and
Moritz Hardt and
Toniann Pitassi and
Omer Reingold and
Richard S. Zemel},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/innovations/DworkHPRZ12.bib},
 booktitle = {Innovations in Theoretical Computer Science 2012, Cambridge, MA, USA,
January 8-10, 2012},
 doi = {10.1145/2090236.2090255},
 editor = {Shafi Goldwasser},
 pages = {214--226},
 publisher = {{ACM}},
 timestamp = {Wed, 14 Nov 2018 10:56:52 +0100},
 title = {Fairness through awareness},
 url = {https://doi.org/10.1145/2090236.2090255},
 year = {2012}
}
@inproceedings{DBLP:conf/kdd/Corbett-DaviesP17,
  author    = {Sam Corbett{-}Davies and
               Emma Pierson and
               Avi Feller and
               Sharad Goel and
               Aziz Huq},
  title     = {Algorithmic Decision Making and the Cost of Fairness},
  booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, Halifax, NS, Canada, August 13
               - 17, 2017},
  pages     = {797--806},
  publisher = {{ACM}},
  year      = {2017},
  url       = {https://doi.org/10.1145/3097983.3098095},
  doi       = {10.1145/3097983.3098095},
  timestamp = {Fri, 25 Dec 2020 01:14:16 +0100},
  biburl    = {https://dblp.org/rec/conf/kdd/Corbett-DaviesP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{barocas-hardt-narayanan,
 author = {Solon Barocas and Moritz Hardt and Arvind Narayanan},
 note = {\url{http://www.fairmlbook.org}},
 publisher = {fairmlbook.org},
 title = {Fairness and Machine Learning},
 year = {2019}
}

@article{Hacker2018_TeachingFairnessToAI,
 author = {Hacker, Philipp},
 journal = {Common Market Law Review},
 number = {4},
 title = {Teaching fairness to artificial intelligence: Existing and novel strategies against algorithmic discrimination under EU law},
 volume = {55},
 year = {2018}
}

@book{Wooldridge2015_IntroductoryMetrics,
 author = {Wooldridge, Jeffrey M},
 publisher = {Cengage Learning},
 title = {Introductory Econometrics: A Modern Approach},
 year = {2015}
}
@inproceedings{quantile2021,
  author    = {Carlos Mougan and
               David Masip and
               Jordi Nin and
               Oriol Pujol},
  editor    = {Vicen{\c{c}} Torra and
               Yasuo Narukawa},
  title     = {Quantile Encoder: Tackling High Cardinality Categorical Features in
               Regression Problems},
  booktitle = {Modeling Decisions for Artificial Intelligence - 18th International
               Conference, {MDAI} 2021, Ume{\aa}, Sweden, September 27-30, 2021,
               Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {12898},
  pages     = {168--180},
  publisher = {Springer},
  year      = {2021},
  url       = {https://doi.org/10.1007/978-3-030-85529-1\_14},
  doi       = {10.1007/978-3-030-85529-1\_14},
  timestamp = {Tue, 21 Sep 2021 19:14:13 +0200},
  biburl    = {https://dblp.org/rec/conf/mdai/MouganMNP21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
